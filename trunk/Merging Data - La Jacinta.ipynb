{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split datos originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creamos función para separar tabla bulk en multiples tablas\n",
    "def getTableBy_datalogger_name(jacintaTable,dl_name):\n",
    "    #Iteramos por columnas buscando dl_name en fila 2 de cada columna\n",
    "    retorno = []\n",
    "    col_list = []\n",
    "    if dl_name != 'datalogger_name':\n",
    "        col_list = ['X1']\n",
    "    col_names = {}\n",
    "    newTable = []\n",
    "    \n",
    "    for i in range(jacintaTable.num_cols()):\n",
    "        if jacintaTable[\"X\" + str(i+1)][0] == dl_name:\n",
    "            col_list.append(\"X\" + str(i+1))\n",
    "            col_names[\"X\" + str(i+1)] = jacintaTable[\"X\" + str(i+1)][1] + ' - ' + jacintaTable[\"X\" + str(i+1)][2] + ' - ' + jacintaTable[\"X\" + str(i+1)][3]\n",
    "    \n",
    "    newTable = jacintaTable[col_list]\n",
    "    #Copiamos de la fila 4 en adelante\n",
    "    newTable = newTable[4:]\n",
    "    col_names['X1'] = 'Timestamp'\n",
    "    newTable.rename(col_names)\n",
    "    retorno = newTable\n",
    "    return retorno\n",
    "\n",
    "# Creamos función para separar por 'device_name' de cada 'datalogger_name'\n",
    "def getTableBy_device_name(jacintaTable,dl_name,dv_name):\n",
    "    #Iteramos por columnas buscando dl_name en fila 2 de cada columna\n",
    "    retorno = []\n",
    "    col_list = []\n",
    "    if dl_name != 'datalogger_name':\n",
    "        col_list = ['X1']\n",
    "    col_names = {}\n",
    "    \n",
    "    for i in range(jacintaTable.num_cols()):\n",
    "        if (jacintaTable[\"X\" + str(i+1)][0] == dl_name) and (jacintaTable[\"X\" + str(i+1)][1] == dv_name):\n",
    "            col_list.append(\"X\" + str(i+1))\n",
    "            col_names[\"X\" + str(i+1)] = jacintaTable[\"X\" + str(i+1)][1] + ' - ' + jacintaTable[\"X\" + str(i+1)][2] + ' - ' + jacintaTable[\"X\" + str(i+1)][3]\n",
    "                \n",
    "\n",
    "    newTable = jacintaTable[col_list]\n",
    "    #Copiamos de la fila 4 en adelante\n",
    "    newTable = newTable[4:]\n",
    "    col_names['X1'] = 'Timestamp'\n",
    "    newTable.rename(col_names)\n",
    "    retorno = newTable\n",
    "    return retorno\n",
    "\n",
    "# Función que crea una lista de los valores que contiene las filas 1 y 2 sin repetidos\n",
    "def getDevicesList(jacintaTable):\n",
    "    devList = []\n",
    "    for i in jacintaTable[0]:\n",
    "        devList.append(jacintaTable[i][0] + '___' + jacintaTable[i][1])\n",
    "    return set(devList)\n",
    "\n",
    "def getDataLoggerList(jt):\n",
    "    loggerList = set(jt[0].values())\n",
    "    return loggerList\n",
    "\n",
    "#Función que recorre la lista de Tablas, separa los datos y los guarda en un CSV con el nombre de la tabla\n",
    "def ProcessData(list,jacintaTable):\n",
    "    for l in list:\n",
    "        sub_table = getTableBy_datalogger_name(jacintaTable,l)\n",
    "        sub_table.export_csv(dst + '/' + str(l) + '.csv',';')\n",
    "        print str(l) + ' process'\n",
    "\n",
    "def ProcessDataComposed(list,jacintaTable):\n",
    "    for l in list:\n",
    "        parts = []\n",
    "        pre = \"\"\n",
    "        suf = \"\"\n",
    "        #Separamos por símbolo '_'\n",
    "        parts = l.split('___')\n",
    "        pre = parts[0]\n",
    "        suf = parts[1]\n",
    "        \n",
    "        sub_table = getTableBy_device_name(jacintaTable,pre,suf)\n",
    "        sub_table.export_csv(dst + '/'  + str(l) + '.csv',';')\n",
    "        print str(l) + ' process'\n",
    "\n",
    "def ResetContext():\n",
    "    logger_list.clear()\n",
    "    dev_list.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-07-01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-07-01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16 lines in 0.016001 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16 lines in 0.016001 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-07-01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-07-01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 16 lines in 0.017001 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 16 lines in 0.017001 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT01 process\n",
      "datalogger_name process\n",
      "CT02 process\n",
      "CT01___Módulo inversor 01.1.4 process\n",
      "CT01___Inversor 01.2 process\n",
      "CT01___Módulo inversor 01.1.1 process\n",
      "CT01___Módulo inversor 01.1.2 process\n",
      "CT01___Módulo inversor 01.1.3 process\n",
      "datalogger_name___device_name process\n",
      "CT02___Inversor 02.1 process\n",
      "CT01___Detector fuego 01 process\n",
      "CT01___Combinador CN1 01.1 process\n",
      "CT01___Combinador CN1 01.2 process\n",
      "CT02___Módulo inversor 02.2.3 process\n",
      "CT02___Módulo inversor 02.2.2 process\n",
      "CT02___Módulo inversor 02.2.1 process\n",
      "CT02___Módulo inversor 02.2.4 process\n",
      "CT01___Módulo inversor 01.2.3 process\n",
      "CT01___Módulo inversor 01.2.2 process\n",
      "CT01___Módulo inversor 01.2.1 process\n",
      "CT01___Inversor 01.1 process\n",
      "CT02___Inversor 02.2 process\n",
      "CT01___Módulo inversor 01.2.4 process\n",
      "### 0716 done ###\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-08-01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-08-01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 25 lines in 0.015001 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 25 lines in 0.015001 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str,str]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-08-01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\test\\2552_2016-08-01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 25 lines in 0.015001 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 25 lines in 0.015001 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT01 process\n",
      "datalogger_name process\n",
      "CT02 process\n",
      "CT01___Módulo inversor 01.1.4 process\n",
      "CT01___Inversor 01.2 process\n",
      "CT01___Módulo inversor 01.1.1 process\n",
      "CT01___Módulo inversor 01.1.2 process\n",
      "CT01___Módulo inversor 01.1.3 process\n",
      "datalogger_name___device_name process\n",
      "CT02___Inversor 02.1 process\n",
      "CT01___Detector fuego 01 process\n",
      "CT01___Combinador CN1 01.1 process\n",
      "CT01___Combinador CN1 01.2 process\n",
      "CT02___Módulo inversor 02.2.3 process\n",
      "CT02___Módulo inversor 02.2.2 process\n",
      "CT02___Módulo inversor 02.2.1 process\n",
      "CT02___Módulo inversor 02.2.4 process\n",
      "CT01___Módulo inversor 01.2.3 process\n",
      "CT01___Módulo inversor 01.2.2 process\n",
      "CT01___Módulo inversor 01.2.1 process\n",
      "CT01___Inversor 01.1 process\n",
      "CT02___Inversor 02.2 process\n",
      "CT01___Módulo inversor 01.2.4 process\n",
      "### 0816 done ###\n"
     ]
    }
   ],
   "source": [
    "# Procesamos datos simplificados\n",
    "src = 'D:/01 - DATA_SRC_01/Jacinta/test/'\n",
    "\n",
    "\n",
    "jac0616 = '2552_2016-06-01.csv'\n",
    "dst = 'D:/01 - DATA_SRC_01/Jacinta/test/0616'\n",
    "\n",
    "jacinta_0616 = graphlab.SFrame.read_csv(src + jac0616, delimiter=';',header= False)\n",
    "\n",
    "#Creamos lista de Tablas\n",
    "logger_list = getDataLoggerList(jacinta_0616)\n",
    "dev_list = getDevicesList(jacinta_0616)\n",
    "#Procesamos los datos separando en tablas\n",
    "ProcessData(logger_list,jacinta_0616)\n",
    "#Procesamos los datos separando en tablas\n",
    "ProcessDataComposed(dev_list,jacinta_0616)\n",
    "print '### 0616 done ###'\n",
    "\n",
    "\n",
    "jac0716 = '2552_2016-07-01.csv'\n",
    "dst = 'D:/01 - DATA_SRC_01/Jacinta/test/0716'\n",
    "\n",
    "jacinta_0716 = graphlab.SFrame.read_csv(src + jac0716, delimiter=';',header= False)\n",
    "\n",
    "#ResetContext()\n",
    "#Creamos lista de Tablas\n",
    "logger_list = getDataLoggerList(jacinta_0716)\n",
    "dev_list = getDevicesList(jacinta_0716)\n",
    "#Procesamos los datos separando en tablas\n",
    "ProcessData(logger_list,jacinta_0716)\n",
    "#Procesamos los datos separando en tablas\n",
    "ProcessDataComposed(dev_list,jacinta_0716)\n",
    "print '### 0716 done ###'\n",
    "\n",
    "\n",
    "jac0816 = '2552_2016-08-01.csv'\n",
    "dst = 'D:/01 - DATA_SRC_01/Jacinta/test/0816'\n",
    "\n",
    "jacinta_0816 = graphlab.SFrame.read_csv(src + jac0816, delimiter=';',header= False)\n",
    "\n",
    "ResetContext()\n",
    "#Creamos lista de Tablas\n",
    "logger_list = getDataLoggerList(jacinta_0816)\n",
    "dev_list = getDevicesList(jacinta_0816)\n",
    "#Procesamos los datos separando en tablas\n",
    "ProcessData(logger_list,jacinta_0816)\n",
    "#Procesamos los datos separando en tablas\n",
    "ProcessDataComposed(dev_list,jacinta_0816)\n",
    "print '### 0816 done ###'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargamos CSVs en SFrames acumulando todos los meses de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función que recorre una lista de carpeta buscando un fichero para mergear sus contenidos en una variable\n",
    "# Supone que todos los CSVs tienen el mismo esquema\n",
    "def MergeFiles(src_list, file_name):\n",
    "    col_types = ()\n",
    "    i = 1\n",
    "    for src in src_list:\n",
    "        if i == 1:\n",
    "            dataFrame = graphlab.SFrame.read_csv(src + file_name, delimiter=';',header= True)\n",
    "            col_types = dataFrame.column_types()\n",
    "            i = i+1\n",
    "        else:\n",
    "            dataFrame = dataFrame.append(graphlab.SFrame.read_csv(src + file_name, delimiter= ';', header = True,column_type_hints=col_types))\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función que recorre una lista de carpeta buscando un fichero para mergear sus contenidos en una variable\n",
    "# Supone que todos los CSVs tienen el mismo esquema\n",
    "def MergeFiles2(src_list, file_name):\n",
    "    col_types = ()\n",
    "    i = 1\n",
    "    for src in src_list:\n",
    "        try:\n",
    "            if i == 1:\n",
    "                dataFrame = graphlab.SFrame.read_csv(src + file_name, delimiter=';',header= True)\n",
    "                col_types = dataFrame.column_types()\n",
    "                i = i+1\n",
    "            else:\n",
    "                dataFrame = dataFrame.append(graphlab.SFrame.read_csv(src + file_name, delimiter= ';', header = True,column_type_hints=col_types))\n",
    "        except:\n",
    "            print src  + file_name + \" - file not found!\"\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Función que recorre lista de files\n",
    "def "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iteramos por carpetas cargando csvs en SFrames\n",
    "# Listamos carpetas a consultar\n",
    "src_list =('D:/01 - DATA_SRC_01/Jacinta/0616/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0716/',\n",
    "          'D:/01 - DATA_SRC_01/Jacinta/0816/')\n",
    "\n",
    "CT01 = MergeFiles(src_list,'CT01.csv')\n",
    "CT01.num_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Iteramos por lista de ficheros\n",
    "file_list = ('CT01',\n",
    "            'CT02',\n",
    "            'CT03',\n",
    "            'CT04',\n",
    "            'CT05',\n",
    "            'CT06')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos Producción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\0616\\CT01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\0616\\CT01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.045002 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.045002 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[str,long,long,long,float,float,float,long,float,long,long,long,long,float,float,float,long,float,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,long,long,long,long,long,long,float,long,float,long,long,float,long,long,long,long,float,long,long,long,long,long,float,float,float,float,float,float,float,float,float,float,float,float,long,float,float,float,float,float,float,float,float,float,float,float,float,long,long]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\0616\\CT01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\0616\\CT01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 2482 lines in 0.060003 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 2482 lines in 0.060003 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\0716\\CT01.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file D:\\01 - DATA_SRC_01\\Jacinta\\0716\\CT01.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 8843 lines in 0.18301 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 8843 lines in 0.18301 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/01 - DATA_SRC_01/Jacinta/0816/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/0916/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/1016/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/1116/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/1216/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/0117/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/0217/CT01.csv - file not found!\n",
      "D:/01 - DATA_SRC_01/Jacinta/0317/CT01.csv - file not found!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11325"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Iteramos por carpetas cargando csvs en SFrames\n",
    "# Listamos carpetas a consultar\n",
    "src_list =('D:/01 - DATA_SRC_01/Jacinta/0616/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0716/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0816/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0916/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/1016/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/1116/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/1216/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0117/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0217/',\n",
    "           'D:/01 - DATA_SRC_01/Jacinta/0317/',)\n",
    "\n",
    "CT01 = MergeFiles2(src_list,'CT01.csv')\n",
    "CT01.num_rows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
